% == this file is about Deep Neural Network

% ==================================================================
%                     Summary
% ==================================================================
%{{{
@article{SPEED_JNeuCom2017_Liu,
  title={A survey of deep neural network architectures and their applications},
  author={Liu, Weibo and Wang, Zidong and Liu, Xiaohui and Zeng, Nianyin and Liu, Yurong and Alsaadi, Fuad E},
  journal={Neurocomputing},
  volume={234},
  pages={11--26},
  year={2017},
  publisher={Elsevier}
}

@article{DL_FTSP2014_Deng,
  title={Deep learning: methods and applications},
  author={Deng, Li and Yu, Dong and others},
  journal={Foundations and Trends{\textregistered} in Signal Processing},
  volume={7},
  number={3--4},
  pages={197--387},
  year={2014}
}
@misc{DL_CS231_Andrej,
    title        = {{Stanford University CS231n: Convolutional Neural Networks for Visual Recognition}},
    author       = {Andrej Karpathy},
    howpublished = {\url{http://cs231n.github.io/neural-networks-3/}}
}
@book{DL_B2009_Haykins,
    title     = {{Neural Networks and Learning Machines}},
    author    = {Haykin, Simon S.},
    year      = {2009},
    publisher = {Pearson Upper Saddle River, NJ, USA:}
}
@article{DL_APSIPA2012_Li,
    title   = {Three classes of deep learning architectures and their applications: a tutorial survey},
    author  = {Deng, Li},
    journal = {APSIPA transactions on signal and information processing},
    year    = {2012},
}
@inproceedings{DL_IJCAI2005_Hinton,
    author    = {Geoffrey E.~Hinton},
    title     = {What kind of graphical model is the brain?},
    booktitle = ijcai,
    pages     = {1765--1775},
    year      = {2005},
    abstract  = {deep learning basis},
} 
@book{DL_MIT2016_Goodfellow,
    title     = {{Deep Learning}},
    author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher = {MIT Press},
    note      = {\url{http://www.deeplearningbook.org}},
    year      = {2016},
}
@article{DL_arXiv2018_Dumoulin,
    title   = {A guide to convolution arithmetic for deep learning},
    author  = {Dumoulin, Vincent and Visin, Francesco},
    journal = {arXiv preprint arXiv:1603.07285},
    year    = {2018},
}
% ==== tools
@inproceedings{DL_ACMMM2014_Caffe,
    title     = {Caffe: Convolutional architecture for fast feature embedding},
    author    = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
    booktitle = acmmm,
    pages     = {675--678},
    year      = {2014},
}
@article{DL_arXiv2014_cuDNN,
    title   = {{cuDNN}: Efficient primitives for deep learning},
    author  = {Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
    journal = arxiv,
    year    = {2014},
}
@inproceedings{DL_NIPSW2016_MXNet,
    title={{MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems}},
    author={Chen, Tianqi and Li, Mu and Li, Yutian and Lin, Min and Wang, Naiyan and Wang, Minjie and Xiao, Tianjun and Xu, Bing and Zhang, Chiyuan and Zhang, Zheng},
    booktitle={NIPS Workshop},
    year={2016}
}
@misc{Caffe_Model_Zoo,
    title  = {Caffe model zoo},
    author = {Jia, Yangqing and Shelhamer, E},
    year   = {2015}
}
@inproceedings{DL_OSDI2016_TensorFlow,
    title     = {{TensorFlow}: A System for Large-scale Machine Learning},
    author    = {Abadi, Mart\'{\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and others},
    booktitle = osdi,
    year      = {2016},
    pages     = {265--283},
} 
@inproceedings{DL_NIPSW2017_PyTorch,
    title     = {Automatic differentiation in {PyTorch}},
    author    = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
    booktitle = {NIPS Workshop},
    year      = {2017},
}

@misc{GPU_NVIDIA_TensorRT,
    title       = {{NVIDIA TensorRT}},
    howpublished = "\url{https://docs.nvidia.com/deeplearning/tensorrt/index.html}",
}

@misc{CPU-Intel_MKL_DNN,
    title       = {{Intel MKL-DNN}},
    howpublished = "\url{https://github.com/oneapi-src/oneDNN}",
}
%}}}


% ==================================================================
%                    Model -- DNN 
% ==================================================================
@inproceedings{DL_ICLR2017_Paleo,
    title     = {Paleo: A performance model for deep neural networks},
    author    = {Qi, Hang and Sparks, Evan R and Talwalkar, Ameet},
    booktitle = iclr,
    year      = {2016},
}
@inproceedings{DL_CVPR2019_ECC,
    title     = {{ECC}: Platform-Independent Energy-Constrained Deep Neural Network Compression via a Bilinear Regression Model},
    author    = {Yang, Haichuan and Zhu, Yuhao and Liu, Ji},
    booktitle = cvpr,
    pages     = {11206--11215},
    year      = {2019},
}
@inproceedings{DL_ICLR2019_Yang,
    title     = {Energy-Constrained Compression for Deep Neural Networks via Weighted Sparse Projection and Layer Input Masking},
    author    = {Yang, Haichuan and Zhu, Yuhao and Liu, Ji},
    booktitle = iclr,
    year      = {2019},
}

% ==================================================================
%                     Training -- DNN
% ==================================================================
%{{{
@article{DL_Nature1986_Rumelhart,
    title   = {Learning representations by back-propagating errors},
    author  = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
    journal = {Nature},
    volume  = {323},
    number  = {6088},
    pages   = {533--536},
    year    = {1986},
}
@article{DL_JUFKBS1998_Sepp,
    title     = {The vanishing gradient problem during learning recurrent neural nets and problem solutions},
    author    = {Hochreiter, Sepp},
    journal   = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
    volume    = {6},
    number    = {02},
    pages     = {107--116},
    year      = {1998},
    publisher = {World Scientific},
}
@inproceedings{DL_FLAIRS2002_Nasr,
    title     = {Cross Entropy Error Function in Neural Networks: Forecasting Gasoline Demand},
    author    = {Nasr, George E. and Badr, E.~A. and Joun, C.},
    booktitle = {FLAIRS Conference},
    pages     = {381--384},
    year      = {2002},
}
@article{DL_NECO2006_Hinton,
    title   = {A fast learning algorithm for deep belief nets},
    author  = {Geoffrey E.~Hinton and Simon Osindero and Yee Whye Teh},
    journal = neco,
    volume  = {18},
    number  = {7},
    pages   = {1527--1554},
    year    = {2006},
}
@inproceedings{DL_AISTATS2010_Glorot,
    title     = {Understanding the difficulty of training deep feedforward neural networks},
    author    = {Glorot, Xavier and Bengio, Yoshua},
    booktitle = aistats,
    volume    = {9},
    pages     = {249--256},
    year      = {2010},
}
@inproceedings{DL_ICML2010_Nair,
    title     = {Rectified linear units improve restricted boltzmann machines},
    author    = {Nair, Vinod and Hinton, Geoffrey E.},
    booktitle = icml,
    pages     = {807--814},
    year      = {2010},
}
@inproceedings{DL_NIPSW2010_Lamblin,
    title     = {Important Gains from Supervised Fine-tuning of Deep Architectures on Large Labeled Sets},
    author    = {Pascal Lamblin and Yoshua Bengio},
    booktitle = {NIPS Workshop on Deep Learning and Unsupervised Feature Learning},
    year      = {2010},
    abstract  = {finetune},
}
@incollection{DL_BC2012_Yoshua,
    title     = {Practical recommendations for gradient-based training of deep architectures},
    author    = {Bengio, Yoshua},
    booktitle = {{Neural Networks: Tricks of the Trade}},
    editor    = {Orr, Genevieve B. and M{\"u}ller, Klaus-Robert},
    pages     = {437--478},
    year      = {2012},
    publisher = {Springer},
}
@inproceedings{DL_ECCV2014_Zeiler,
    title     = {Visualizing and understanding convolutional networks},
    author    = {Zeiler, Matthew D. and Fergus, Rob},
    booktitle = eccv,
    pages     = {818--833},
    year      = {2014},
}
@article{DL_JMLR2014_Nitish,
    title   = {Dropout: a simple way to prevent neural networks from overfitting.},
    author  = {Srivastava, Nitish and Hinton, Geoffrey E. and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
    journal = jmlr,
    volume  = {15},
    number  = {1},
    pages   = {1929--1958},
    year    = {2014},
}
@inproceedings{DL_CVPR2015_Szegedy,
    title     = {Going deeper with convolutions},
    author    = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
    booktitle = cvpr,
    pages     = {1--9},
    year      = {2015},
    abstract  = {GoogleNet},
}
@inproceedings{DL_AISTATS2015_Choromanska,
    title     = {The Loss Surfaces of Multilayer Networks},
    author    = {Choromanska, Anna and Henaff, MIkael and Mathieu, Michael and Ben Arous, Gerard and LeCun, Yann},
    booktitle = aistats,
    pages     = {192--204},
    year      = {2015},
}
@article{DL_ICLR2015_Simonyan,
    title   = {Very deep convolutional networks for large-scale image recognition},
    author  = {Simonyan, Karen and Zisserman, Andrew},
    journal = iclr,
    year    = {2015},
}
@inproceedings{DL_ICLR2015_Adam,
    title     = {Adam: A method for stochastic optimization},
    author    = {Kingma, Diederik P and Ba, Jimmy},
    booktitle = iclr,
    year      = {2015},
}
@article{DL_TSP2015_Giryes,
    title     = {Deep Neural Networks with Random Gaussian Weights: A Universal Classification Strategy?},
    author    = {Giryes, Raja and Sapiro, Guillermo and Bronstein, Alex M.},
    journal   = tsp,
    volume    = {64},
    number    = {13},
    pages     = {3444--3457},
    year      = {2015},
    publisher = {IEEE},
}
@article{DL_arXiv2016_Mishkin,
    title   = {Systematic evaluation of {CNN} advances on the {ImageNet}},
    author  = {Mishkin, Dmytro and Sergievskiy, Nikolay and Matas, Jiri},
    journal = arxiv,
    year    = {2016},
}
@inproceedings{DL_ECCV2016_Huang,
    title        = {Deep networks with stochastic depth},
    author       = {Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
    booktitle    = eccv,
    pages        = {646--661},
    year         = {2016},
}
@inproceedings{DL_ICLR2017_Raghu,
    title     = {On the expressive power of deep neural networks},
    author    = {Raghu, Maithra and Poole, Ben and Kleinberg, Jon and Ganguli, Surya and Sohl-Dickstein, Jascha},
    booktitle = iclr,
    year      = {2017},
}
@techreport{DL_CBMM2017_Zhang,
    title       = {Theory of Deep Learning {III}: Generalization Properties of {SGD}},
    author      = {Zhang, Chiyuan and Liao, Qianli and Rakhlin, Alexander and Sridharan, Karthik and Miranda, Brando and Golowich, Noah and Poggio, Tomaso},
    year        = {2017},
    institution = {Center for Brains, Minds and Machines (CBMM)},
}
# ==== CNNSGD
@article{DL_CMMP1964_Polyak,
    title     = {Some methods of speeding up the convergence of iteration methods},
    author    = {Polyak, Boris T.},
    journal   = {USSR Computational Mathematics and Mathematical Physics},
    volume    = {4},
    number    = {5},
    pages     = {1--17},
    year      = {1964},
    publisher = {Elsevier},
}
@incollection{DL_BC2012_Bottou,
    title     = {Stochastic gradient descent tricks},
    author    = {Bottou, L{\'e}on},
    booktitle = {{Neural networks: Tricks of the Trade}},
    editor    = {Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
    pages     = {421--436},
    year      = {2012},
    publisher = {Springer},
}
@article{DL_NIPS1995_Moody,
    title   = {A simple weight decay can improve generalization},
    author  = {Moody, J. and Hanson, S. and Krogh, Anders and Hertz, John A.},
    journal = nips,
    volume  = {4},
    pages   = {950--957},
    year    = {1995},
}
@article{DL_ICML2013_Sutskever,
    title   = {On the importance of initialization and momentum in deep learning.},
    author  = {Sutskever, Ilya and Martens, James and Dahl, George E. and Hinton, Geoffrey E.},
    journal = icml,
    volume  = {28},
    pages   = {1139--1147},
    year    = {2013},
}
@inproceedings{DL_ICLR2018_Yang,
    title     = {Breaking the softmax bottleneck: A high-rank {RNN} language model},
    author    = {Yang, Zhilin and Dai, Zihang and Salakhutdinov, Ruslan and Cohen, William W},
    booktitle = iclr,
    year      = {2018}
}
%}}}


% ==================================================================
%                    Structure -- RNN
% ==================================================================
@incollection{RNN_BC2001_Sepp,
    title     = {Gradient flow in recurrent nets: the difficulty of learning long-term dependencies},
    author    = {Hochreiter, Sepp and Bengio, Yoshua and Frasconi, Paolo and Schmidhuber, J{\"u}rgen},
    booktitle = {{A Field Guide to Dynamical Recurrent Neural Networks}},
    editor    = {Kolen, John F. and Kremer, Stefan C.},
    publisher = {IEEE Press},
    year      = {2001},
}


% ==================================================================
%              Structure -- adaptive-NN
% ==================================================================
@inproceedings{DL_ICCAD2018_Stamoulis,
    title     = {Designing Adaptive Neural Networks for Energy-constrained Image Classification},
    author    = {Stamoulis, Dimitrios and Chin, Ting-Wu (Rudy) and Prakash, Anand Krishnan and Fang, Haocheng and Sajja, Sribhuvan and Bognar, Mitchell and Marculescu, Diana},
    booktitle = iccad,
    pages     = {23:1--23:8},
    year      = {2018},
    abstract  = {also discuss DNN energy model},
}

% ==================================================================
%              Structure -- Generative Model
% ==================================================================
% == GAN
%{{{
@incollection{GAN_NIPS2014_Ian,
    title     = {Generative Adversarial Nets},
    author    = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = nips,
    pages     = {2672--2680},
    year      = {2014},
}
@article{GAN_arXiv2014_Mirza,
    title   = {Conditional generative adversarial nets},
    author  = {Mirza, Mehdi and Osindero, Simon},
    journal = {arXiv preprint arXiv:1411.1784},
    year    = {2014}
}
@inproceedings{GAN_NIPS2016_Liu,
    title     = {Coupled generative adversarial networks},
    author    = {Liu, Ming-Yu and Tuzel, Oncel},
    booktitle = nips,
    pages     = {469--477},
    year      = {2016},
}
@inproceedings{GAN_ICLR2016_DCGAN,
	title     = {Unsupervised representation learning with deep convolutional generative adversarial networks},
	author    = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	booktitle = iclr,
	year      = {2016},
    abstract  = {DC-GAN},
}
@inproceedings{GAN_ICLR2017_Arjovsky,
    title     = {Towards Principled Methods for Training Generative Adversarial Networks},
    author    = {Arjovsky, Martin and Bottou, L{\'e}on},
    booktitle = iclr,
    year      = {2016},
    abstract  = {W-GAN version 1},
}
@inproceedings{GAN_ICCV2017_Zhu,
    title     = {Unpaired image-to-image translation using cycle-consistent adversarial networks},
    author    = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
    booktitle = iccv,
    year      = {2017},
}
@inproceedings{GAN_ICML2017_WGAN,
    title     = {Wasserstein generative adversarial networks},
    author    = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
    booktitle = icml,
    pages     = {214--223},
    year      = {2017},
    abstract  = {W-GAN version 2},
}
@inproceedings{GAN_NIPS2017_WGAN,
    title     = {Improved training of wasserstein {GANs}},
    author    = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
    booktitle = nips,
    pages     = {5767--5777},
    year      = {2017},
    abstract  = {W-GAN version 3},
}
% === applications of GAN
@inproceedings{GAN_SOCC2017_Liu,
    title     = {Generative adversarial network based scalable on-chip noise sensor placement},
    author    = {Liu, Jinglan and Ding, Yukun and Yang, Jianlei and Schlichtmann, Ulf and Shi, Yiyu},
    booktitle = socc,
    pages     = {239--242},
    year      = {2017},
}
@inproceedings{GAN_ASPDAC2018_Chen,
    title     = {{ReGAN}: A pipelined {ReRAM}-based accelerator for generative adversarial networks},
    author    = {Chen, Fan and Song, Linghao and Chen, Yiran},
    booktitle = aspdac,
    pages     = {178--183},
    year      = {2018},
}
%}}}
% == Auto-Encoder
@inproceedings{AE_ICANN2011_Masci,
    title     = {Stacked convolutional auto-encoders for hierarchical feature extraction},
    author    = {Masci, Jonathan and Meier, Ueli and Cire{\c{s}}an, Dan and Schmidhuber, J{\"u}rgen},
    booktitle = icann,
    pages     = {52--59},
    year      = {2011},
}
@inproceedings{AE_ICANN2011_Hinton,
    title     = {Transforming auto-encoders},
    author    = {Hinton, Geoffrey E and Krizhevsky, Alex and Wang, Sida D},
    booktitle = icann,
    pages     = {44--51},
    year      = {2011},
}


% =========================================
%         Structure -- CoordNet 
% =========================================
@inproceedings{DL_NIPS2018_CoordConv,
    title     = {An intriguing failing of convolutional neural networks and the coordconv solution},
    author    = {Liu, Rosanne and Lehman, Joel and Molino, Piero and Such, Felipe Petroski and Frank, Eric and Sergeev, Alex and Yosinski, Jason},
    booktitle = nips,
    pages     = {9605--9616},
    year      = {2018},
}
@article{DL_arXiv2018_Nibali,
    title   = {Numerical coordinate regression with convolutional neural networks},
    author  = {Nibali, Aiden and He, Zhen and Morgan, Stuart and Prendergast, Luke},
    journal = {arXiv preprint arXiv:1801.07372},
    year    = {2018},
}





